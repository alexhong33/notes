### 第七章
* section 1
	* Scrapy 架构解析
* Section 2 
	* User-Agent 解析
	* 设置随即取UA		 





1. 无状态请求
2. 有状态请求

#### 常见httpcode
* 200 : 请求被成功处理
* 301/302 : 永久性重定向/临时性重定向
* 403 : 没有权限访问
* 404 : 表示没有对应的资源
* 500 : 服务器错误
* 503 : 服务器停机或正在维护


#### 爬虫策略

1. User-agent模拟firefox, 获取ip代理
2. 注册账号, 每次请求带cookie或者token
3. 注册多个账号, 多个账号联合爬取
4. 模仿人请求, 限制请求速度
5. 通过各种手段识别验证码
6. 通过selenium和phantomjs完全模拟浏览器操作


#### 反爬虫策略

1. 监控发现某个时间段访问剧增, ip相同, user-agent是python,直接限制访问(不能封ip)
2. 发现ip变化, 直接要求登录才能访问
3. 健全账号体系, A只能访问好友的信息
4. 请求过于频繁, 进一步加剧ip访问频率限制
5. 弹出验证码, 让识别验证码
6.  * 增加动态网站, 数据通过js动态加载, 增加网络分析复杂
	* 发现大量请求只请求html,不请求image和css以及js
	 